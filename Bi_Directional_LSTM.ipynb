{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32yCsRUo8H33"
   },
   "source": [
    "# 2024 COMP90042 Project\n",
    "*Make sure you change the file name with your group id.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCybYoGz8YWQ"
   },
   "source": [
    "# Readme\n",
    "*If there is something to be noted for the marker, please mention here.*\n",
    "\n",
    "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6po98qVA8bJD"
   },
   "source": [
    "# 1.DataSet Processing\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvff21Hv8zjk"
   },
   "source": [
    "### Read Files to get raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def readJsFile(filename) :\n",
    "    return json.load(open(filename,'r'))\n",
    "\n",
    "def save_data(data, filename):\n",
    "    json.dump(data, open(filename, \"w\"))\n",
    "\n",
    "def load_data(filename):\n",
    "    return json.load(open(filename, \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' define functions to preprocess raw texts with tokenization, lemmatization, and remove stopwords'''\n",
    "import nltk,re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "tt = TweetTokenizer()\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "stopwords = set(stopwords.words('english'))     # note: stopwords are all in lowercase\n",
    "\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "    \n",
    "def preprocess_text(text):\n",
    "    # Tokenization and lemmatization\n",
    "    tokens = tt.tokenize(text.lower())\n",
    "    tokens = [lemmatize(t) for t in tokens]\n",
    "    \n",
    "    # remove any word that does not contain any English letters,\n",
    "    # including punctuation\n",
    "    valid_tokens = []\n",
    "    for t in tokens:\n",
    "        if re.search(r\"[a-z]\",t):\n",
    "            valid_tokens.append(t)\n",
    "\n",
    "    # remove stop words\n",
    "    tokens = []\n",
    "    for t in valid_tokens:\n",
    "        if t not in stopwords:\n",
    "            tokens.append(t)\n",
    "\n",
    "    # resemble processed tokens back to text\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "'not' in stopwords and 'no' in stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split raw data into **claim-texts, cliam-ids**, & **claim-labels** & **evidences list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, isTest=False, isEvd=False):\n",
    "    ids = []\n",
    "    text = []\n",
    "    labels = []\n",
    "    evidences = []\n",
    "\n",
    "    # split test data\n",
    "    if isTest and not isEvd:\n",
    "        for claim_id, data in data.items():\n",
    "            ids.append(claim_id)\n",
    "            text.append(preprocess_text(data['claim_text']))\n",
    "    # split evidences\n",
    "    elif isEvd and not isTest:\n",
    "        for evidence_id, data in data.items():\n",
    "            evidences.append(preprocess_text(data))\n",
    "    # split train data\n",
    "    elif not isTest and not isEvd:\n",
    "        for claim_id, data in data.items():\n",
    "            ids.append(claim_id)\n",
    "            text.append(preprocess_text(data['claim_text']))\n",
    "            labels.append(data['claim_label'])\n",
    "            evidences.append(data['evidences'])\n",
    "    else:\n",
    "        print('Wrong Mode, please check your arguments: isTest and isEvd')\n",
    "        \n",
    "    return ids, text, labels, evidences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Prepare raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw data\n",
    "train_data= readJsFile('data/train-claims.json')\n",
    "dev_data = readJsFile('data/dev-claims.json')\n",
    "test_data = readJsFile('data/test-claims-unlabelled.json')\n",
    "all_evidences = readJsFile('data/evidence.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract, transform data to lists\n",
    "train_ids, train_texts, train_labels, train_evidences = split_data(train_data)\n",
    "test_ids, test_texts, _, _ = split_data(test_data, isTest=True)\n",
    "dev_ids, dev_texts, dev_labels, dev_evidences = split_data(dev_data)\n",
    "_,_,_, evidences_lst = split_data(all_evidences, isEvd=True) # this step is time-consuming"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# save data for debugging\n",
    "# please comment the code out when submmiting\n",
    "\n",
    "save_data(train_ids, 'temp_data/train_ids.json')\n",
    "save_data(train_texts, 'temp_data/train_texts.json')\n",
    "save_data(train_labels, 'temp_data/train_labels.json')\n",
    "save_data(train_evidences, 'temp_data/train_evidences.json')\n",
    "\n",
    "save_data(dev_ids, 'temp_data/dev_ids.json')\n",
    "save_data(dev_texts, 'temp_data/dev_texts.json')\n",
    "save_data(dev_labels, 'temp_data/dev_labels.json')\n",
    "save_data(dev_evidences, 'temp_data/dev_evidences.json')\n",
    "\n",
    "save_data(test_ids, 'temp_data/test_ids.json')\n",
    "save_data(test_texts, 'temp_data/test_texts.json')\n",
    "\n",
    "save_data(evidences_lst, 'temp_data/evidences_lst.json')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# load saved data\n",
    "# please comment the code out when submmiting\n",
    "\n",
    "train_ids = load_data(\"temp_data/train_ids.json\")\n",
    "train_texts = load_data(\"temp_data/train_texts.json\")\n",
    "train_labels = load_data(\"temp_data/train_labels.json\")\n",
    "train_evidences = load_data(\"temp_data/train_evidences.json\")\n",
    "\n",
    "dev_ids = load_data(\"temp_data/dev_ids.json\")\n",
    "dev_texts = load_data(\"temp_data/dev_texts.json\")\n",
    "dev_labels = load_data(\"temp_data/dev_labels.json\")\n",
    "dev_evidences = load_data(\"temp_data/dev_evidences.json\")\n",
    "\n",
    "test_ids = load_data(\"temp_data/test_ids.json\")\n",
    "test_texts = load_data(\"temp_data/test_texts.json\")\n",
    "\n",
    "evidences_lst = load_data(\"temp_data/evidences_lst.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify data correctness\n",
    "# print(train_texts[0])\n",
    "# evidences_lst[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 tfidf word embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1210055, 500000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = evidences_lst + train_texts              # text documents\n",
    "vectorizer = TfidfVectorizer(max_features=500000) # initialization\n",
    "\n",
    "# Fit the vectorizer to the data and transform the documents into TF-IDF vectors\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.shape)\n",
    "\n",
    "# To see the feature names (terms)\n",
    "#feature_names = vectorizer.get_feature_names_out()\n",
    "#print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1228, 500000)\n",
      "(154, 500000)\n",
      "(153, 500000)\n",
      "(1208827, 500000)\n"
     ]
    }
   ],
   "source": [
    "# transform data into tf-idf vectors\n",
    "\n",
    "train_tfidf = vectorizer.transform(train_texts)\n",
    "print(train_tfidf.shape)\n",
    "\n",
    "dev_tfidf = vectorizer.transform(dev_texts)\n",
    "print(dev_tfidf.shape)\n",
    "\n",
    "test_tfidf = vectorizer.transform(test_texts)\n",
    "print(test_tfidf.shape)\n",
    "\n",
    "evidence_tfidf = vectorizer.transform(evidences_lst)\n",
    "print(evidence_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1228, 1208827)\n",
      "(153, 1208827)\n",
      "(154, 1208827)\n"
     ]
    }
   ],
   "source": [
    "# calculate cosine similarity\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "train_cos_sims = cosine_similarity(train_tfidf, evidence_tfidf) # needs large memory\n",
    "print(train_cos_sims.shape)\n",
    "\n",
    "test_cos_sims = cosine_similarity(test_tfidf, evidence_tfidf)\n",
    "print(test_cos_sims.shape)\n",
    "\n",
    "dev_cos_sims = cosine_similarity(dev_tfidf, evidence_tfidf)\n",
    "print(dev_cos_sims.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we cannot use 1208827 intances in our training process\n",
    "# we have to evaluate and decide how many information will be disposed\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# def top_n_indices(ls, n):\n",
    "#     ''' Returns indices of the 20 highest numbers.'''\n",
    "#     sorted_indices = sorted(range(len(ls)), key=lambda i: ls[i], reverse=True)\n",
    "#     return sorted_indices[:n]\n",
    "\n",
    "def top_n_similarity_recall(n, cos_sims, evidences):\n",
    "    '''\n",
    "    Calculates the recall of correct evidences within the top N evidences with the highest similarity scores.\n",
    "\n",
    "    Parameters:\n",
    "        n (int): Represents the number of top similarity score items to select.\n",
    "        cos_sims (2D-list): A list where each item contains similarity score of a train text with all evidence text.\n",
    "        evidences (2D-list): A list wheere each item contains all correct evidences for each train text .\n",
    "\n",
    "    Returns:\n",
    "        The proportion of correct evidences among the top N evidences, relative to the total number of correct evidences.\n",
    "    '''\n",
    "    res = []\n",
    "    for i in range(cos_sims.shape[0]):\n",
    "        # retreive evidence_id of top n scores\n",
    "        scores = cos_sims[i]\n",
    "        # topn_idx = top_n_indices(scores, n)\n",
    "        topn_idx = np.argpartition(scores, -n)[-n:] # more efficient, find indecies of topn elements in the list\n",
    "        \n",
    "        total = 0\n",
    "        recall = 0\n",
    "        # count number of evidences we find in topn evidences\n",
    "        for e in evidences[i]:\n",
    "            e_id = int(e.split('-')[1]) # e = evidence-xxxx\n",
    "            if e_id in topn_idx:\n",
    "                recall += 1\n",
    "            total += 1\n",
    "        res.append(recall / total)\n",
    "    return sum(res) / len(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this step is time-consuming\n",
    "# topns = [100, 200, 500, 1000]\n",
    "# for topn in topns:\n",
    "#     train_recall = top_n_similarity_recall(topn,train_cos_sims, train_evidences)\n",
    "#     dev_recall   = top_n_similarity_recall(topn,dev_cos_sims,dev_evidences)\n",
    "#     print(topn,train_recall, dev_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topn = 100\n",
    "# train_recall = top_n_similarity_recall(topn,train_cos_sims, train_evidences)\n",
    "# dev_recall   = top_n_similarity_recall(topn,dev_cos_sims,dev_evidences)\n",
    "# print(f'topn:{topn}, train: {train_recall}, dev: {dev_recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topn = 200\n",
    "# train_recall = top_n_similarity_recall(topn,train_cos_sims, train_evidences)\n",
    "# dev_recall   = top_n_similarity_recall(topn,dev_cos_sims,dev_evidences)\n",
    "# print(topn,train_recall, dev_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topn = 500\n",
    "# train_recall = top_n_similarity_recall(topn,train_cos_sims, train_evidences)\n",
    "# dev_recall   = top_n_similarity_recall(topn,dev_cos_sims,dev_evidences)\n",
    "# print(topn,train_recall, dev_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topn = 1000\n",
    "# train_recall = top_n_similarity_recall(topn,train_cos_sims, train_evidences)\n",
    "# dev_recall   = top_n_similarity_recall(topn,dev_cos_sims,dev_evidences)\n",
    "# print(topn,train_recall, dev_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Nagetive sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' find correct evidences from parts of evidences rather than all evidences, for example, first 1000 evidences instead of 120887\n",
    "    transform the multi-class classification problem to binary classification'''\n",
    "\n",
    "def nagetive_sampling(cos_sims, texts, evidences, all_evidence, topn, isTrain=False):\n",
    "    samples = []\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    for i in range(cos_sims.shape[0]):  # text similarity with all evidence texts\n",
    "        # samples\n",
    "        if isTrain:  \n",
    "            # use all positive trainning data during training process\n",
    "            for e in evidences[i]:\n",
    "                e_id = int(e.split('-')[1]) # e = evidence-xxxx\n",
    "                data.append('<cls> ' + texts[i] + '<sep> ' + all_evidence[e_id])  # combine Query and Document, like BERT\n",
    "                label.append(1)\n",
    "            # topn_ids = np.argsort(-cos_sims[i])[:topn].tolist()\n",
    "            topn_ids = np.argsort(-cos_sims[i])[25:topn+25].tolist() # dispose first 25 items with highest sim-score\n",
    "        else: # we take only topn samples in test sets\n",
    "            topn_ids = np.argpartition(cos_sims[i], -topn)[-topn:].tolist()\n",
    "        samples.append(topn_ids)\n",
    "\n",
    "        # labels & data\n",
    "        for j in topn_ids:\n",
    "            data.append('<cls>' + texts[i] + '<sep>' + all_evidence[j])\n",
    "            # if current evidence is one of the correct ones, label it true\n",
    "            j = 'evidence-'+str(j)\n",
    "            if evidences is not None: # some test data have no relative evidences\n",
    "                if j in evidences[i]:\n",
    "                    label.append(1)\n",
    "                else:\n",
    "                    label.append(0)\n",
    "\n",
    "    return samples, data, label\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn = 200\n",
    "train_ns_samples, train_ns_data, train_ns_label = nagetive_sampling(\n",
    "    train_cos_sims, train_texts, train_evidences, evidences_lst, topn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ns_samples, dev_ns_data, dev_ns_label = nagetive_sampling(\n",
    "    dev_cos_sims, dev_texts, dev_evidences, evidences_lst, topn, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ns_samples, test_ns_data, _ = nagetive_sampling(\n",
    "    test_cos_sims, test_texts, None, evidences_lst, topn, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Counter({0: 244630, 1: 5092})\n",
      "percentage of label 0: 0.9796093255700339\n",
      "training set set label ratio: 48.04202670856245\n",
      "\n",
      "Dev: Counter({0: 30555, 1: 245})\n",
      "percentage of label 0: 0.9920454545454546\n",
      "development set set label ratio: 124.71428571428571\n",
      "\n",
      "ratio: 48.04202670856245\n"
     ]
    }
   ],
   "source": [
    "# data inspection\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "train_ns_label = np.array(train_ns_label)\n",
    "dev_ns_label = np.array(dev_ns_label)\n",
    "\n",
    "t_ct = Counter(train_ns_label)\n",
    "d_ct = Counter(dev_ns_label)\n",
    "\n",
    "print(\"Train:\",t_ct)\n",
    "print(\"percentage of label 0:\",t_ct[0] / (t_ct[0] + t_ct[1]))\n",
    "print('training set set label ratio:',t_ct[0] / t_ct[1])\n",
    "print()\n",
    "print(\"Dev:\",d_ct)\n",
    "print(\"percentage of label 0:\",d_ct[0] / (d_ct[0] + d_ct[1]))\n",
    "print('development set set label ratio:',d_ct[0] / d_ct[1])\n",
    "print()\n",
    "ratio = t_ct[0] / t_ct[1]\n",
    "print('ratio:',ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Keras transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 17:18:58.309723: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38652\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(train_ns_data) \n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # padding\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenise the input into word sequences\n",
    "\n",
    "train_seq = tokenizer.texts_to_sequences(train_ns_data)\n",
    "dev_seq = tokenizer.texts_to_sequences(dev_ns_data)\n",
    "test_seq = tokenizer.texts_to_sequences(test_ns_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249722 39 11\n"
     ]
    }
   ],
   "source": [
    "print(len(train_seq),len(train_seq[0]),len(dev_seq[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n",
      "167\n",
      "maxlen: 207\n"
     ]
    }
   ],
   "source": [
    "# padding matrix to the same length\n",
    "\n",
    "max_i = 0\n",
    "for i in train_seq:\n",
    "    max_i = max(max_i, len(i))\n",
    "max_t = max_i\n",
    "print(max_t)\n",
    "\n",
    "max_i = 0\n",
    "for i in dev_seq:\n",
    "    max_i = max(max_i, len(i))\n",
    "max_v = max_i\n",
    "print(max_v)\n",
    "\n",
    "maxlen = max_t if max_v <= max_t else max_v\n",
    "print('maxlen:',maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_seq = pad_sequences(train_seq, padding='post', maxlen=maxlen)\n",
    "dev_seq = pad_sequences(dev_seq, padding='post', maxlen=maxlen)\n",
    "test_seq = pad_sequences(test_seq, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249722"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FA2ao2l8hOg"
   },
   "source": [
    "# 2. Model Implementation\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "QIEqDDT78q39",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import LSTM\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "def LSTM_Model():\n",
    "    # TODO: fine-tunning\n",
    "    embedding_dim = 60\n",
    "    hidden_dim = 100\n",
    "\n",
    "    # model\n",
    "    model = Sequential(name=\"LSTM_G6\")\n",
    "\n",
    "    # embedding layer\n",
    "    model.add(layers.Embedding(\n",
    "        input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen))\n",
    "\n",
    "    ##\n",
    "    ## experiments here to verify what technology is effective\n",
    "    ##\n",
    "\n",
    "    # one direction\n",
    "    # model.add(layers.Dropout(0.1)) # increase robustness using dropout\n",
    "    # model.add(LSTM(hidden_dim, return_sequences=True, dropout=0.1)) # double layer\n",
    "    # model.add(LSTM(hidden_dim, dropout=0.1))                        # single layer - baseline\n",
    "\n",
    "    # bidirectional\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Bidirectional(LSTM(hidden_dim, return_sequences=True, dropout=0.1)))\n",
    "    model.add(layers.Bidirectional(LSTM(hidden_dim, dropout=0.1)))\n",
    "\n",
    "    # output layer\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(hidden_dim // 2, activation='tanh'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    ## finish the model construction\n",
    "\n",
    "    # Exponential Decay Learning Rate Scheduler\n",
    "    initial_learning_rate = 1e-2\n",
    "    decay_steps = 1000\n",
    "    decay_rate = 0.96\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps, decay_rate, staircase=True\n",
    "    )\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    # binary cross entropy loss for binary classification problem\n",
    "    # model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras.metrics.Recall()])\n",
    "    # model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM_G6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 207, 60)           2319120   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 207, 60)           0         \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 207, 200)         128800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 200)              240800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 50)                10050     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,698,821\n",
      "Trainable params: 2,698,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# implement the LSTM Model\n",
    "model = LSTM_Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Imbalanced data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampling(sampler,train_seq,train_ns_label,dev_seq,dev_ns_label):\n",
    "    train_seq_res, train_ns_label_res = sampler.fit_resample(train_seq, train_ns_label)\n",
    "\n",
    "    t_ct = Counter(train_ns_label_res)\n",
    "    ratio = t_ct[0] / t_ct[1]\n",
    "    print(t_ct)\n",
    "\n",
    "    dev_seq_res, dev_ns_label_res = sampler.fit_resample(dev_seq, dev_ns_label)\n",
    "    print(Counter(dev_ns_label_res))\n",
    "    print('ratio:',ratio)\n",
    "    \n",
    "    return train_seq_res, train_ns_label_res,dev_seq_res, dev_ns_label_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "sm = SMOTE(random_state=426)\n",
    "# resampling(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "adsyn = ADASYN(random_state=426)\n",
    "# resampling(adsyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=426)\n",
    "# resampling(rus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Oversampling and Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smote_enn = SMOTETomek(random_state=426)\n",
    "# resampling(smote_enn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Start Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM_G6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, 207, 60)           2319120   \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 207, 60)           0         \n",
      "                                                                 \n",
      " bidirectional_20 (Bidirecti  (None, 207, 200)         128800    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_21 (Bidirecti  (None, 200)              240800    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 50)                10050     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,698,821\n",
      "Trainable params: 2,698,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set set label ratio: 48.04202670856245\n"
     ]
    }
   ],
   "source": [
    "# without resamplinng\n",
    "X = train_seq\n",
    "y = train_ns_label\n",
    "dev_X = dev_seq\n",
    "dev_y = dev_ns_label\n",
    "t_ct = Counter(train_ns_label)\n",
    "ratio = t_ct[0] / t_ct[1]\n",
    "print('training set set label ratio:',t_ct[0] / t_ct[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 5092, 1: 5092})\n",
      "Counter({0: 245, 1: 245})\n",
      "ratio: 1.0\n"
     ]
    }
   ],
   "source": [
    "# resampling\n",
    "sampler = rus\n",
    "train_seq_res, train_ns_label_res,dev_seq_res, dev_ns_label_res = resampling(\n",
    "    sampler,train_seq,train_ns_label,dev_seq,dev_ns_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resampling\n",
    "X = train_seq_res\n",
    "y = train_ns_label_res\n",
    "dev_X = dev_seq_res\n",
    "dev_y = dev_ns_label_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainning\n",
    "ratio = 1\n",
    "\n",
    "model.fit(X, y, \n",
    "      epochs=15, verbose=True, \n",
    "      validation_data=(dev_X, dev_y), \n",
    "      batch_size=1000, class_weight={0: 1, 1: ratio})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzGuzHPE87Ya"
   },
   "source": [
    "# 3.Testing and Evaluation\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "\n",
    "dev_pred = model.predict(dev_seq, batch_size=1000, verbose=True)\n",
    "test_pred = model.predict(test_seq, batch_size=1000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dev_pred[:4], dev_pred.shape, test_pred.shape, len(dev_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select evidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evidences(pred, ns_samples, select_k, topn):\n",
    "    start_idx = 0\n",
    "    pred_evidences = []\n",
    "    count_idx = 0\n",
    "    \n",
    "    while start_idx < len(pred):\n",
    "        end_idx = start_idx + topn\n",
    "        cur_pred = pred[start_idx : end_idx]\n",
    "        cur_top_ids = np.argpartition(-cur_pred.squeeze(), select_k)[:select_k].tolist()\n",
    "        pred_evidences.append( ['evidence-'+str(ns_samples[count_idx][i]) for i in cur_top_ids])\n",
    "        start_idx = end_idx\n",
    "        count_idx += 1\n",
    "    return pred_evidences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select evidences\n",
    "\n",
    "select_evidence_k = 6\n",
    "test_evidences_ids = get_evidences(\n",
    "    test_pred, test_ns_samples, select_evidence_k, topn)\n",
    "\n",
    "dev_evidences_ids = get_evidences(\n",
    "    dev_pred, dev_ns_samples, select_evidence_k, topn)\n",
    "\n",
    "print(dev_evidences_ids[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate Evidence Retrieval F-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Evidence Retrieval F-score\n",
    "\n",
    "f = []\n",
    "for idx, evidence_ids in enumerate(dev_evidences_ids):\n",
    "\n",
    "    #check retrieved evidences\n",
    "    evidence_correct = 0\n",
    "    evidence_recall = 0.0\n",
    "    evidence_precision = 0.0\n",
    "    evidence_fscore = 0.0\n",
    "    \n",
    "    for cur_id in evidence_ids:\n",
    "        if cur_id in dev_evidences[idx]:\n",
    "            evidence_correct += 1\n",
    "    \n",
    "    if evidence_correct > 0:\n",
    "        evidence_recall = evidence_correct / len(dev_evidences[idx])\n",
    "        evidence_precision = evidence_correct / len(evidence_ids)\n",
    "        evidence_fscore = (2*evidence_precision*evidence_recall)/(evidence_precision+evidence_recall)\n",
    "    f.append(evidence_fscore)\n",
    "\n",
    "#compute aggregate performance\n",
    "mean_f = np.mean(f if len(f) > 0 else [0.0])\n",
    "print(\"Evidence Retrieval F-score (F)    =\", mean_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_sufix = \"_smote_enn0.0380\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_dev_evd_retrieval_bidirectM_adsyn0.0380.json\n"
     ]
    }
   ],
   "source": [
    "pred_dev_evd_file = \"pred_dev_evd_retrieval_bidirectM\"+file_sufix+\".json\"\n",
    "pred_test_evd_file = \"pred_test_evd_retrieval_bidirectM\"+file_sufix+\".json\"\n",
    "print(pred_dev_evd_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save evidences selected\n",
    "\n",
    "pred_dev_claims = {}\n",
    "pred_test_claims = {}\n",
    "\n",
    "for idx, evidence_ids in enumerate(dev_evidences_ids):\n",
    "    cur_data = dev_data[dev_ids[idx]]\n",
    "    cur_data['evidences'] = evidence_ids\n",
    "    pred_dev_claims[dev_ids[idx]] = cur_data\n",
    "    # print(pred_dev_claims)\n",
    "    # break\n",
    "\n",
    "for idx, evidence_ids in enumerate(test_evidences_ids):\n",
    "    cur_data = test_data[test_ids[idx]]\n",
    "    cur_data['evidences'] = evidence_ids\n",
    "    pred_test_claims[test_ids[idx]] = cur_data\n",
    "    # break\n",
    "    \n",
    "## save prediction data\n",
    "json.dump(pred_dev_claims, open(pred_dev_evd_file, \"w\"))\n",
    "json.dump(pred_test_claims, open(pred_test_evd_file, \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mefSOe8eTmGP"
   },
   "source": [
    "## Object Oriented Programming codes here\n",
    "\n",
    "*You can use multiple code snippets. Just add more if needed*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
