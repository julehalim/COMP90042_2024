{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2024 COMP90042 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the marker, please mention here.*\n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.DataSet Processing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "## package imports\n",
        "\n",
        "#!pip install pandas scikit-learn torch torchtext\n",
        "\n",
        "## deep-learning libraries\n",
        "import tensorflow\n",
        "import torch\n",
        "import keras\n",
        "\n",
        "## NLP preprocessing libraries\n",
        "import nltk\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "##others\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import string\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "qvff21Hv8zjk"
      },
      "outputs": [],
      "source": [
        "## reading in json files\n",
        "\n",
        "\"\"\"\n",
        "Description of json files\n",
        "* [train-claims,dev-claims].json: JSON files for the labelled training and development set; \n",
        "* evidence.json: JSON file containing a large number of evidence passages (i.e. the “knowledge source”); \n",
        "* dev-claims-baseline.json: JSON file containing predictions of a baseline system on the development set;\n",
        "\"\"\"\n",
        "\n",
        "## relative file paths\n",
        "\n",
        "## baseline system - will not be used for any training/evaluation\n",
        "devClaimsBaselineFile='./data/dev-claims-baseline.json'\n",
        "## use this for model training\n",
        "trainClaimsFile='./data/train-claims.json'\n",
        "## use this set for hyperparameter tuning and evaluation metric \n",
        "devClaimsFile='./data/dev-claims.json'\n",
        "## evidence files need to be downloaded through https://drive.google.com/file/d/1JlUzRufknsHzKzvrEjgw8D3n_IRpjzo6/view?usp=sharing as it is to big to be uploaded to github\n",
        "evidenceFile='./data/evidence.json'\n",
        "\n",
        "## import as pandas dataframe\n",
        "devClaimsBaseline=pd.read_json(devClaimsBaselineFile)\n",
        "trainClaims=pd.read_json(trainClaimsFile)\n",
        "devClaims=pd.read_json(devClaimsFile)\n",
        "evidence=pd.read_json(evidenceFile,orient='index')\n",
        "\n",
        "## Separate claim_text,claim_label, and evidences from training and development sets, saved as pd dataframes\n",
        "claimTextTrain=trainClaims.loc['claim_text'].to_frame()\n",
        "claimLabelTrain=trainClaims.loc['claim_label'].to_frame()\n",
        "evidenceTrain=trainClaims.loc['evidences'].to_frame()\n",
        "\n",
        "claimTextDev=devClaims.loc['claim_text'].to_frame()\n",
        "claimLabelDev=devClaims.loc['claim_label'].to_frame()\n",
        "evidenceDev=devClaims.loc['evidences'].to_frame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Obtain the evidence texts and add it as a new column at the evidence pd dataframes\n",
        "## This is in place transformation, but should always overwrite the evidence_text column so does not matter\n",
        "\n",
        "def getTextEvidence(evidenceList):\n",
        "    texts=[]\n",
        "    for evidenceID in evidenceList:\n",
        "        text=evidence.loc[evidenceID]\n",
        "        texts.append(text)\n",
        "    return texts\n",
        "\n",
        "## keeps the original df to visually check that evidences are correct\n",
        "evidenceDev['evidence_text']=evidenceDev['evidences'].apply(getTextEvidence)\n",
        "evidenceTrain['evidence_text']=evidenceTrain['evidences'].apply(getTextEvidence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Preprocessing data -- lowercase, tokenize, and stopword removal\n",
        "stopwords=set(nltk.corpus.stopwords.words('english'))\n",
        "punctuations=string.punctuation\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens=nltk.word_tokenize(text.lower())\n",
        "    cleanedTokens=[t for t in tokens if (t not in stopwords) and (t not in punctuations)]\n",
        "    return ' '.join(cleanedTokens)\n",
        "\n",
        "claimTextDev['claim_text']=claimTextDev['claim_text'].apply(preprocess)\n",
        "claimTextTrain['claim_text']=claimTextTrain['claim_text'].apply(preprocess)\n",
        "\n",
        "##used to preprocess evidence, as structure is a bit different for evidence and claim dataframes\n",
        "for sentence,i in zip(evidenceDev['evidence_text'],range(len(evidenceDev['evidence_text']))):\n",
        "    for n in range(len(sentence)):\n",
        "        evidenceDev['evidence_text'][i][n]=evidenceDev['evidence_text'][i][n].apply(preprocess)\n",
        "        \n",
        "for sentence,i in zip(evidenceTrain['evidence_text'],range(len(evidenceTrain['evidence_text']))):\n",
        "    for n in range(len(sentence)):\n",
        "        evidenceTrain['evidence_text'][i][n]=evidenceTrain['evidence_text'][i][n].apply(preprocess)\n",
        "\n",
        "\n",
        "\n",
        "## evidence only pd dataframes\n",
        "evidenceDevText=evidenceDev['evidence_text']\n",
        "evidenceTrainText=evidenceTrain['evidence_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 2042)\t0.25465864193776144\n",
            "  (0, 365)\t0.3357179817735733\n",
            "  (0, 2584)\t0.286016675105824\n",
            "  (0, 3357)\t0.31737470827388653\n",
            "  (0, 1188)\t0.286016675105824\n",
            "  (0, 1691)\t0.29426491672830174\n",
            "  (0, 257)\t0.25465864193776144\n",
            "  (0, 795)\t0.3043599486055108\n",
            "  (0, 1707)\t0.23386936307954653\n",
            "  (0, 2612)\t0.286016675105824\n",
            "  (0, 739)\t0.29443543623449897\n",
            "  (0, 1302)\t0.19798354634541807\n",
            "  (0, 3043)\t0.22723701033370075\n",
            "  (1, 1221)\t0.20758727315332845\n",
            "  (1, 2108)\t0.25488353480179354\n",
            "  (1, 2123)\t0.2847129492318619\n",
            "  (1, 2163)\t0.2512059813791188\n",
            "  (1, 2970)\t0.2091785370685991\n",
            "  (1, 3338)\t0.37394155546435687\n",
            "  (1, 3418)\t0.19264623027283195\n",
            "  (1, 1582)\t0.13904851359976036\n",
            "  (1, 1711)\t0.3586071279012528\n",
            "  (1, 2829)\t0.22087131783386782\n",
            "  (1, 1164)\t0.3955542172359483\n",
            "  (1, 2357)\t0.3046853775095814\n",
            "  :\t:\n",
            "  (1226, 63)\t0.2342925590059373\n",
            "  (1226, 3149)\t0.15874178134371789\n",
            "  (1226, 3767)\t0.25254064703344437\n",
            "  (1226, 3690)\t0.2394769713283662\n",
            "  (1226, 1768)\t0.1291513741773741\n",
            "  (1226, 3483)\t0.17927437646263644\n",
            "  (1226, 3417)\t0.132884199886591\n",
            "  (1226, 2284)\t0.2297195832477417\n",
            "  (1227, 2274)\t0.2619888368324643\n",
            "  (1227, 2778)\t0.2619888368324643\n",
            "  (1227, 928)\t0.2619888368324643\n",
            "  (1227, 1062)\t0.2619888368324643\n",
            "  (1227, 1204)\t0.2619888368324643\n",
            "  (1227, 3647)\t0.2619888368324643\n",
            "  (1227, 1857)\t0.2619888368324643\n",
            "  (1227, 374)\t0.2619888368324643\n",
            "  (1227, 2214)\t0.2619888368324643\n",
            "  (1227, 2453)\t0.2619888368324643\n",
            "  (1227, 3076)\t0.2619888368324643\n",
            "  (1227, 2153)\t0.2375175392521176\n",
            "  (1227, 1421)\t0.22963954104265485\n",
            "  (1227, 1512)\t0.2232027478236264\n",
            "  (1227, 1683)\t0.20888795639513516\n",
            "  (1227, 3712)\t0.15367239485074882\n",
            "  (1227, 2036)\t0.13697661465416658\n"
          ]
        }
      ],
      "source": [
        "## use TF-IDF word embedding\n",
        "\n",
        "tfidfVector=TfidfVectorizer()\n",
        "x=tfidfVector.fit_transform(claimTextTrain['claim_text'])\n",
        "print(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2. Model Implementation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIEqDDT78q39"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZVeNYIH9IaL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefSOe8eTmGP"
      },
      "source": [
        "## Object Oriented Programming codes here\n",
        "\n",
        "*You can use multiple code snippets. Just add more if needed*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
